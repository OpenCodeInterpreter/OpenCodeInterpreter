# OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement

<p align="center">
<img width="1000px" alt="OpenCodeInterpreter" src="https://opencodeinterpreter.github.io/static/images/figure1.png">
</p>
<p align="center">
  <a href="https://opencodeinterpreter.github.io/">[ğŸ Homepage]</a> 
  |
  <a href="https://github.com/OpenCodeInterpreter/OpenCodeInterpreter/">[ğŸ› ï¸Code]</a> 
</p>
<hr>

## ğŸŒŸ Upcoming Features

- ğŸ“ˆ **Adding OpenCodeInterpreter-DS-1.3b Model:** 

- ğŸ’¡ **Introducing OpenCodeInterpreter-GM-7b Model with gemma-7b Base:** 

- ğŸ“Š **Open Sourcing CodeFeedback-Filtered-Instruction Dataset:** 

- ğŸš€ **Deploying Demo on HuggingFace Spaces:** 

- ğŸ› ï¸ **Open Sourcing Demo Local Deployment Code with a Setup Guide:** 

## ğŸ””News
ğŸš€[2024-02-23]: We have open-sourced the datasets used in our project named Code-Feedback.

ğŸ”¥[2024-02-19]: We have open-sourced all models in the OpenCodeInterpreter series ! We welcome everyone to try out our models and look forward to your participation! ğŸ˜†



## Introduction
OpenCodeInterpreter is a suite of open-source code generation systems aimed at bridging the gap between large language models and sophisticated proprietary systems like the GPT-4 Code Interpreter. It significantly enhances code generation capabilities by integrating execution and iterative refinement functionalities.

## Models
All models within the OpenCodeInterpreter series have been open-sourced on Hugging Face. You can access our models via the following link: [OpenCodeInterpreter Models](https://huggingface.co/collections/m-a-p/opencodeinterpreter-65d312f6f88da990a64da456).

## Data Collection
Supported by Code-Feedback, a dataset featuring 68K multi-turn interactions, OpenCodeInterpreter incorporates execution and human feedback for dynamic code refinement. 
For additional insights into data collection procedures, please consult the readme provided under [Data Collection](https://github.com/OpenCodeInterpreter/OpenCodeInterpreter/blob/main/data_collection/README.md).

## Evaluation
Our evaluation framework primarily utilizes HumanEval and MBP, alongside their extended versions, HumanEval+ and MBPP+, leveraging the [EvalPlus framework](https://github.com/evalplus/evalplus) for a more comprehensive assessment.
For specific evaluation methodologies, please refer to the [Evaluation README](https://github.com/OpenCodeInterpreter/OpenCodeInterpreter/blob/main/evaluation/README.md) for more details.

## Contact

If you have any inquiries, please feel free to raise an issue or reach out to us via email at: xiangyue.work@gmail.com, zhengtianyu0428@gmail.com. 
We're here to assist you!
